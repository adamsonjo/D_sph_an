import requests
import praw
import re
import time
import os
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime
from dotenv import load_dotenv

load_dotenv()

# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –±–∞–∑–æ–≤—ã–π —É—Ä–æ–≤–µ–Ω—å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)

# URL —Å–ª–æ–≤–∞—Ä—è BIP-39 –Ω–∞ GitHub
url = "https://raw.githubusercontent.com/bitcoin/bips/master/bip-0039/english.txt"

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∏ –∑–∞–≥—Ä—É–∑–∫–∏ —Å–ª–æ–≤–∞—Ä—è BIP-39
def download_bip39_words(url):
    try:
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –Ω–∞ –ø–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
        response = requests.get(url)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Å–ø–µ—à–Ω–æ—Å—Ç—å –∑–∞–ø—Ä–æ—Å–∞
        if response.status_code == 200:
            # –†–∞–∑–¥–µ–ª—è–µ–º —Å–ª–æ–≤–∞ –ø–æ —Å—Ç—Ä–æ–∫–∞–º
            bip39_words = response.text.strip().split("\n")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Å–ø–∏—Å–æ–∫ –Ω–µ –ø—É—Å—Ç
            if not bip39_words:
                logging.warning("–°–ª–æ–≤–∞—Ä—å –ø—É—Å—Ç–æ–π!")
                return []
            
            logging.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(bip39_words)} —Å–ª–æ–≤ –∏–∑ BIP-39.")
            return bip39_words
        else:
            logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Å–ª–æ–≤–∞—Ä—è: {response.status_code}")
            return []
    except requests.exceptions.RequestException as e:
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ –∑–∞–ø—Ä–æ—Å–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –æ—à–∏–±–∫–∏ —Å–µ—Ç–∏)
        logging.error(f"–û—à–∏–±–∫–∞ —Å–µ—Ç–∏: {e}")
        return []

# –ó–∞–≥—Ä—É–∑–∫–∞ —Å–ª–æ–≤–∞—Ä—è BIP-39
bip39_words = download_bip39_words(url)

# –ï—Å–ª–∏ —Å–ª–æ–≤–∞—Ä—å –∑–∞–≥—Ä—É–∂–µ–Ω, –Ω–∞–ø—Ä–∏–º–µ—Ä, —Å–æ—Ö—Ä–∞–Ω—è–µ–º –µ–≥–æ –≤ —Ñ–∞–π–ª
if bip39_words:
    with open("bip39_words.txt", "w") as file:
        for word in bip39_words:
            file.write(f"{word}\n")
    logging.info("–°–ª–æ–≤–∞—Ä—å BIP-39 —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ —Ñ–∞–π–ª bip39_words.txt.")

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Reddit API —á–µ—Ä–µ–∑ praw
reddit = praw.Reddit(
    client_id=os.getenv('client_id'),  # –í–∞—à client_id
    client_secret=os.getenv('client_secret'),  # –í–∞—à client_secret
    user_agent="SeedPhraseParser u/SuspiciousUse22",  # –í–∞—à user_agent
)

# --------------- –ó–ê–ì–†–£–ó–ö–ê –°–õ–û–í–ê–†–Ø BIP-39 ----------------
def load_bip39_wordlist(path="bip39_words.txt"):
    try:
        with open(path, "r", encoding="utf-8") as f:
            return set(word.strip() for word in f if word.strip())
    except FileNotFoundError:
        print(f"‚ùå –§–∞–π–ª {path} –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü–æ–º–µ—Å—Ç–∏—Ç–µ BIP-39 —Å–ª–æ–≤–∞—Ä—å —Ä—è–¥–æ–º —Å–æ —Å–∫—Ä–∏–ø—Ç–æ–º.")
        exit(1)

# --------------- –ò–ó–í–õ–ï–ß–ï–ù–ò–ï –§–†–ê–ó –ò –°–õ–û–í ----------------
def extract_seed_elements(text, bip39_words):
    words = re.findall(r'\b[a-z]+\b', text.lower())
    valid_words = [w for w in words if w in bip39_words]

    unique_phrases = set()
    single_words = set(valid_words)  # —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞

    def extract_chunks(size):
        for i in range(len(valid_words) - size + 1):
            chunk = valid_words[i:i+size]
            phrase = " ".join(chunk)
            unique_phrases.add(phrase)

    extract_chunks(12)
    extract_chunks(24)

    return unique_phrases, single_words

# --------------- –§–ò–õ–¨–¢–† –ü–û –î–ê–¢–ï ----------------
def is_post_in_date_range(post_date, start_date, end_date):
    return start_date <= post_date <= end_date

# --------------- –ü–ê–†–°–ò–ù–ì –û–î–ù–û–ì–û –°–ê–ë–†–ï–î–î–ò–¢–ê ----------------
def parse_subreddit(subreddit_name, start_date, end_date, bip39_words, time_filter="all"):
    print(f"üîç –ü–∞—Ä—Å–∏–º: r/{subreddit_name}")
    phrases = set()
    singles = set()
    try:
        subreddit = reddit.subreddit(subreddit_name)
        for submission in subreddit.top(limit=100000, time_filter=time_filter):
            post_date = datetime.utcfromtimestamp(submission.created_utc)
            if is_post_in_date_range(post_date, start_date, end_date):
                p1, s1 = extract_seed_elements(submission.title, bip39_words)
                p2, s2 = extract_seed_elements(submission.selftext, bip39_words)
                phrases.update(p1)
                phrases.update(p2)
                singles.update(s1)
                singles.update(s2)
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤ r/{subreddit_name}: {e}")
    return phrases, singles

# --------------- –ü–ê–†–°–ò–ù–ì –ù–ï–°–ö–û–õ–¨–ö–ò–• –°–ê–ë–†–ï–î–î–ò–¢–û–í ----------------
def parse_multiple_subreddits(subreddits, start_date, end_date, bip39_words, time_filter="all"):
    all_phrases = set()
    all_single_words = set()
    with ThreadPoolExecutor(max_workers=5) as executor:
        futures = {
            executor.submit(parse_subreddit, sub, start_date, end_date, bip39_words, time_filter): sub
            for sub in subreddits
        }
        for future in as_completed(futures):
            phrases, singles = future.result()
            all_phrases.update(phrases)
            all_single_words.update(singles)
    return all_phrases, all_single_words

# --------------- –°–û–•–†–ê–ù–ï–ù–ò–ï ----------------
def save_to_file(items, filename):
    try:
        with open(filename, "w", encoding="utf-8") as f:
            for item in sorted(items):
                f.write(item + "\n")
        print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(items)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π –≤ {filename}")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ {filename}: {e}")

# --------------- –î–ê–¢–ê ----------------
def parse_date(date_str):
    return datetime.strptime(date_str, "%Y-%m-%d")

# --------------- –ì–õ–ê–í–ù–´–ô –ó–ê–ü–£–°–ö ----------------
if __name__ == "__main__":
    bip39_words = load_bip39_wordlist("bip39_words.txt")

    # –ü–µ—Ä–∏–æ–¥ –∞–Ω–∞–ª–∏–∑–∞
    start_date = parse_date("2023-01-01")
    end_date = parse_date("2025-05-20")

    # –°–ø–∏—Å–æ–∫ —Å–∞–±—Ä–µ–¥–¥–∏—Ç–æ–≤
    subreddits = [
        "CryptoCurrency", "Bitcoin", "ethereum", "CryptoMarkets",
        "seedstorage", "CryptoTechnology", "dogecoin", "solana",
        "blockchain", "Stellar", "btc"
    ]

    # –ü–∞—Ä—Å–∏–º Reddit
    full_phrases, single_words = parse_multiple_subreddits(
        subreddits, start_date, end_date, bip39_words, time_filter="all"
    )

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º
    save_to_file(full_phrases, "only_full_phrases.txt")
    save_to_file(single_words, "single_bip39_words.txt")

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# –í–∞—à GitHub —Ç–æ–∫–µ–Ω
GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')

# –ë–∞–∑–æ–≤—ã–π URL GitHub API
API_BASE = "https://api.github.com"

# –†–µ–≥—É–ª—è—Ä–Ω–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –ø–æ–∏—Å–∫–∞ seed-—Ñ—Ä–∞–∑
SEED_REGEX = re.compile(r"\b(?:[a-z]{3,}\s){11,23}[a-z]{3,}\b", re.IGNORECASE)

# –ó–∞–≥—Ä—É–∑–∫–∞ —Å–ª–æ–≤–∞—Ä—è BIP-39
def load_bip39_wordlist():
    url = "https://raw.githubusercontent.com/bitcoin/bips/master/bip-0039/english.txt"
    response = requests.get(url)
    if response.status_code == 200:
        return set(response.text.strip().split("\n"))
    else:
        logging.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å BIP-39 —Å–ª–æ–≤–∞—Ä—å")
        return set()

# –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è seed-—Ñ—Ä–∞–∑ –∏–∑ —Ç–µ–∫—Å—Ç–∞
def extract_seed_phrases(text, bip39_words):
    phrases = []
    for match in SEED_REGEX.findall(text):
        words = match.lower().split()
        if all(word in bip39_words for word in words):
            phrases.append(" ".join(words))
    return phrases

# –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤ —Å —Ç–µ–º–æ–π bip39
def get_repositories_with_topic(topic, token):
    headers = {
        "Authorization": f"token {token}",
        "Accept": "application/vnd.github.v3+json"
    }
    repos = []
    page = 1
    while True:
        url = f"{API_BASE}/search/repositories?q=topic:{topic}&page={page}&per_page=100"
        response = requests.get(url, headers=headers)
        if response.status_code != 200:
            logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤: {response.status_code}")
            break
        data = response.json()
        if not data['items']:
            break
        repos.extend(data['items'])
        page += 1
    return repos

# –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Ñ–∞–π–ª–æ–≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è
def fetch_seed_phrases_from_repo(owner, repo, bip39_words, token):
    headers = {
        "Authorization": f"token {token}",
        "Accept": "application/vnd.github.v3+json"
    }
    seeds = []
    contents_url = f"{API_BASE}/repos/{owner}/{repo}/contents"
    try:
        response = requests.get(contents_url, headers=headers)
        if response.status_code != 200:
            logging.warning(f"–û—à–∏–±–∫–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ {owner}/{repo}: {response.status_code}")
            return []

        files = response.json()
        for file in files:
            if file["type"] == "file" and file["name"].endswith((".txt", ".md", ".py", ".js")):
                file_resp = requests.get(file["download_url"])
                if file_resp.status_code == 200:
                    seeds += extract_seed_phrases(file_resp.text, bip39_words)
                time.sleep(1)  # –ó–∞–¥–µ—Ä–∂–∫–∞ –¥–ª—è –æ–±—Ö–æ–¥–∞ –ª–∏–º–∏—Ç–∞
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {owner}/{repo}: {e}")
    return seeds

# –û—Å–Ω–æ–≤–Ω–æ–π –∑–∞–ø—É—Å–∫
if __name__ == "__main__":
    bip39_words = load_bip39_wordlist()
    all_seeds = []

    repos = get_repositories_with_topic("bip39", GITHUB_TOKEN)
    logging.info(f"–ù–∞–π–¥–µ–Ω–æ {len(repos)} —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤ —Å —Ç–µ–º–æ–π 'bip39'.")

    for repo in repos:
        owner = repo['owner']['login']
        name = repo['name']
        logging.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ {owner}/{name}...")
        seeds = fetch_seed_phrases_from_repo(owner, name, bip39_words, GITHUB_TOKEN)
        all_seeds.extend(seeds)

    if all_seeds:
        with open("seed_phrases_from_github.txt", "w", encoding="utf-8") as f:
            for phrase in all_seeds:
                f.write(phrase + "\n")
        logging.info(f"–ù–∞–π–¥–µ–Ω–æ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(all_seeds)} seed-—Ñ—Ä–∞–∑.")
    else:
        logging.warning("Seed-—Ñ—Ä–∞–∑—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")